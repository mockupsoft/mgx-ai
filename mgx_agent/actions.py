# -*- coding: utf-8 -*-
"""
MGX Agent Actions Module

LLM Ã§aÄŸrÄ±larÄ± yapan Action sÄ±nÄ±flarÄ±:
- AnalyzeTask: GÃ¶rev karmaÅŸÄ±klÄ±k analizi
- DraftPlan: GÃ¶rev planÄ± taslaÄŸÄ±
- WriteCode: Kod yazma
- WriteTest: Test yazma
- ReviewCode: Kod inceleme
"""

import re
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from metagpt.actions import Action
from metagpt.logs import logger


def llm_retry():
    """LLM Ã§aÄŸrÄ±larÄ± iÃ§in retry decorator"""
    return retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        before_sleep=lambda retry_state: logger.warning(
            f"âš ï¸ LLM hatasÄ±, yeniden deneniyor... (Deneme {retry_state.attempt_number}/3)"
        )
    )


def print_step_progress(step: int, total: int, description: str, role=None):
    """AdÄ±m adÄ±m progress gÃ¶ster
    
    Args:
        step: Mevcut adÄ±m
        total: Toplam adÄ±m
        description: AÃ§Ä±klama
        role: Role instance (team referansÄ± iÃ§in)
    """
    # EÄŸer role'un team referansÄ± varsa onu kullan (config kontrolÃ¼ iÃ§in)
    if role and hasattr(role, '_team_ref') and hasattr(role._team_ref, '_print_progress'):
        role._team_ref._print_progress(step, total, description)
        return
    
    # Fallback: Global fonksiyon (eski davranÄ±ÅŸ)
    bar_length = 20
    filled = int(bar_length * step / total)
    bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
    percent = int(100 * step / total)
    print(f"\r[{bar}] {percent}% - {description}", end="", flush=True)
    if step == total:
        print()  # Yeni satÄ±r


def print_phase_header(phase: str, emoji: str = "ğŸ”„"):
    """Faz baÅŸlÄ±ÄŸÄ± yazdÄ±r"""
    print(f"\n{'='*60}")
    print(f"{emoji} {phase}")
    print(f"{'='*60}")


class AnalyzeTask(Action):
    """GÃ¶revi analiz et (stack-aware)"""
    
    PROMPT_TEMPLATE: str = """GÃ¶rev: {task}
{stack_context}

AÅŸaÄŸÄ±daki formatÄ± kullanarak gÃ¶revi analiz et:

KARMAÅIKLIK: [XS/S/M/L/XL]
Ã–NERÄ°LEN_STACK: [stack_id] - [kÄ±sa gerekÃ§e]
DOSYA_MANÄ°FESTO:
- [dosya1.ext]: [aÃ§Ä±klama]
- [dosya2.ext]: [aÃ§Ä±klama]
TEST_STRATEJÄ°SÄ°: [hangi test framework kullanÄ±lacak ve kaÃ§ test]

Kurallar:
- KARMAÅIKLIK: XS (tek fonksiyon), S (birkaÃ§ fonksiyon), M (modÃ¼l), L (Ã§oklu modÃ¼l), XL (sistem)
- Ã–NERÄ°LEN_STACK: {available_stacks} listesinden seÃ§
- DOSYA_MANÄ°FESTO: OluÅŸturulacak/deÄŸiÅŸtirilecek dosyalarÄ± listele
- TEST_STRATEJÄ°SÄ°: Hangi test framework ve kaÃ§ test yazÄ±lacaÄŸÄ±nÄ± belirt"""
    
    name: str = "AnalyzeTask"
    
    @llm_retry()
    async def run(self, task: str, target_stack: str = None) -> str:
        try:
            # Stack context oluÅŸtur
            from .stack_specs import STACK_SPECS, infer_stack_from_task
            
            available_stacks = ", ".join(STACK_SPECS.keys())
            
            if target_stack:
                stack_context = f"\nHedef Stack: {target_stack}"
            else:
                inferred = infer_stack_from_task(task)
                stack_context = f"\nÃ–nerilen Stack: {inferred} (gÃ¶rev aÃ§Ä±klamasÄ±ndan tahmin edildi)"
            
            prompt = self.PROMPT_TEMPLATE.format(
                task=task,
                stack_context=stack_context,
                available_stacks=available_stacks
            )
            rsp = await self._aask(prompt)
            return rsp
        except Exception as e:
            logger.error(f"âŒ AnalyzeTask hatasÄ±: {e}")
            raise


class DraftPlan(Action):
    """Plan taslaÄŸÄ± oluÅŸtur (stack-aware)"""
    
    PROMPT_TEMPLATE: str = """GÃ¶rev: {task}

Analiz: {analysis}
{stack_info}

KÄ±sa ve Ã¶z plan yaz. SADECE ÅŸu formatÄ± kullan:

1. Kod yaz ({stack_name}) - Alex (Engineer)
2. Test yaz ({test_framework}) - Bob (Tester)  
3. Review yap - Charlie (Reviewer)

AÃ§Ä±klama veya detay YAZMA. SADECE numaralÄ± listeyi yaz."""
    
    name: str = "DraftPlan"
    
    @llm_retry()
    async def run(self, task: str, analysis: str, target_stack: str = None) -> str:
        try:
            # Stack bilgisi ekle
            from .stack_specs import get_stack_spec, infer_stack_from_task
            
            if not target_stack:
                target_stack = infer_stack_from_task(task)
            
            spec = get_stack_spec(target_stack)
            if spec:
                stack_info = f"\nStack: {spec.name}"
                stack_name = spec.language.upper()
                test_framework = spec.test_framework
            else:
                stack_info = ""
                stack_name = "Python"
                test_framework = "pytest"
            
            prompt = self.PROMPT_TEMPLATE.format(
                task=task,
                analysis=analysis,
                stack_info=stack_info,
                stack_name=stack_name,
                test_framework=test_framework
            )
            rsp = await self._aask(prompt)
            return rsp
        except Exception as e:
            logger.error(f"âŒ DraftPlan hatasÄ±: {e}")
            raise


class WriteCode(Action):
    """Kod yaz (stack-aware, multi-language, FILE manifest)"""
    
    PROMPT_TEMPLATE: str = """
GÃ¶rev: {instruction}
Plan: {plan}
Stack: {stack_name}
Dil: {language}
{constraints_section}

{review_section}

{strict_mode_instructions}

ADIM 1 - DÃœÅÃœN (YALNIZCA METÄ°N):

- Bu gÃ¶revi nasÄ±l Ã§Ã¶zeceÄŸini 3â€“7 madde halinde kÄ±saca aÃ§Ä±kla.
- Hangi fonksiyonlarÄ±/component'leri yazacaÄŸÄ±nÄ± ve hangi kÃ¼tÃ¼phaneleri kullanacaÄŸÄ±nÄ± belirt.
- Edge case (uÃ§ durum) olarak neleri dikkate alacaÄŸÄ±nÄ± yaz.
- Hangi dosyalarÄ± oluÅŸturacaÄŸÄ±nÄ±/deÄŸiÅŸtireceÄŸini listele.
- Bu dÃ¼ÅŸÃ¼nce kÄ±smÄ±nda HÄ°Ã‡BÄ°R KOD yazma.

ADIM 2 - KODLA (FILE MANÄ°FEST FORMATINI KULLAN):

{file_format_instructions}

{revision_instructions}
"""
    
    FILE_FORMAT_STRICT: str = """
AÅŸaÄŸÄ±daki FILE manifest formatÄ±nÄ± KULLAN (aÃ§Ä±klama yasak, sadece dosyalar):

FILE: path/to/file1.{ext}
[dosya1 iÃ§eriÄŸi]

FILE: path/to/file2.{ext}
[dosya2 iÃ§eriÄŸi]

Ã–NEMLÄ°: 
- HER DOSYA "FILE: " ile baÅŸlamalÄ±
- Dosya yollarÄ± stack yapÄ±sÄ±na uygun olmalÄ±: {expected_structure}
- AÃ§Ä±klama veya yorum YAZMA, sadece FILE bloklarÄ±
"""
    
    FILE_FORMAT_NORMAL: str = """
AÅŸaÄŸÄ±daki FILE manifest formatÄ±nÄ± veya code block formatÄ±nÄ± kullan:

SEÃ‡ENEK 1 - FILE Manifest (Ã§oklu dosya iÃ§in):
FILE: path/to/file1.{ext}
[dosya1 iÃ§eriÄŸi]

FILE: path/to/file2.{ext}
[dosya2 iÃ§eriÄŸi]

SEÃ‡ENEK 2 - Code Block (tek dosya iÃ§in):
```{language}
# kod buraya
```

Ã–nerilen dosya yapÄ±sÄ±: {expected_structure}
"""
    
    name: str = "WriteCode"
    
    @llm_retry()
    async def run(
        self, 
        instruction: str, 
        plan: str = "", 
        review_notes: str = "",
        target_stack: str = None,
        constraints: list = None,
        strict_mode: bool = False,
        enable_validation: bool = True,
        max_validation_retries: int = 2
    ) -> str:
        try:
            # Stack bilgisi
            from .stack_specs import get_stack_spec, infer_stack_from_task
            from .guardrails import validate_output_constraints, build_revision_prompt
            
            if not target_stack:
                target_stack = infer_stack_from_task(instruction)
            
            spec = get_stack_spec(target_stack)
            if spec:
                stack_name = spec.name
                language = spec.language
                ext = spec.file_extensions[0] if spec.file_extensions else "txt"
                expected_structure = ", ".join(list(spec.project_layout.keys())[:5])
            else:
                stack_name = "Python"
                language = "python"
                ext = ".py"
                expected_structure = "src/, tests/"
            
            # Constraints
            constraints_section = ""
            if constraints:
                constraints_section = f"\nKÄ±sÄ±tlamalar:\n" + "\n".join(f"- {c}" for c in constraints)
            
            # Review notlarÄ±
            review_section = ""
            revision_instructions = ""
            if review_notes and review_notes.strip():
                review_section = f"""
Review NotlarÄ± (Ä°yileÅŸtirme Ã–nerileri):
{review_notes}
"""
                revision_instructions = f"""
Ã–NEMLÄ°: Bu bir dÃ¼zeltme turu. YukarÄ±daki review notlarÄ±nÄ± dikkate alarak mevcut kodu GÃœNCELLE / Ä°YÄ°LEÅTÄ°R.
Orijinal gÃ¶revi unutma: {instruction}
"""
            
            # Strict mode
            strict_mode_instructions = ""
            if strict_mode:
                file_format_instructions = self.FILE_FORMAT_STRICT.format(
                    ext=ext,
                    expected_structure=expected_structure
                )
                strict_mode_instructions = "âš ï¸ STRICT MODE: Sadece FILE bloklarÄ± yaz, hiÃ§bir aÃ§Ä±klama ekleme!"
            else:
                file_format_instructions = self.FILE_FORMAT_NORMAL.format(
                    ext=ext,
                    language=language,
                    expected_structure=expected_structure
                )
            
            # Main generation loop with validation retry
            validation_retry_count = 0
            final_output = None
            validation_result = None
            
            while validation_retry_count <= max_validation_retries:
                prompt = self.PROMPT_TEMPLATE.format(
                    instruction=instruction,
                    plan=plan,
                    stack_name=stack_name,
                    language=language,
                    constraints_section=constraints_section,
                    review_section=review_section,
                    strict_mode_instructions=strict_mode_instructions,
                    file_format_instructions=file_format_instructions,
                    revision_instructions=revision_instructions
                )
                rsp = await self._aask(prompt)
                
                # Parse output based on mode
                if strict_mode:
                    output = rsp  # FILE manifest formatÄ±nda
                else:
                    output = self._parse_code(rsp, language)
                
                # Run validation if enabled
                if enable_validation:
                    validation_result = validate_output_constraints(
                        generated_output=output,
                        stack_spec=spec,
                        constraints=constraints,
                        strict_mode=strict_mode
                    )
                    
                    if validation_result.is_valid:
                        logger.info(f"âœ… Output validation passed: {validation_result.summary()}")
                        final_output = output
                        break
                    else:
                        # Validation failed
                        logger.warning(f"âŒ Output validation failed (attempt {validation_retry_count + 1}/{max_validation_retries + 1})")
                        logger.warning(f"Errors: {len(validation_result.errors)}, Warnings: {len(validation_result.warnings)}")
                        
                        for i, error in enumerate(validation_result.errors[:5], 1):
                            logger.warning(f"  {i}. {error}")
                        
                        if validation_retry_count < max_validation_retries:
                            # Build revision prompt with validation errors
                            revision_prompt = build_revision_prompt(validation_result, instruction)
                            review_notes = revision_prompt
                            validation_retry_count += 1
                            logger.info(f"ğŸ”„ Retrying with validation error feedback...")
                        else:
                            # Max retries reached
                            logger.error(f"âŒ Validation failed after {max_validation_retries + 1} attempts")
                            logger.error("Returning output with validation errors (marked as NEEDS_INFO)")
                            final_output = output
                            break
                else:
                    # Validation disabled
                    final_output = output
                    break
            
            # Log final validation status
            if enable_validation and validation_result and not validation_result.is_valid:
                error_summary = "\n".join(f"  - {e}" for e in validation_result.errors)
                logger.error(
                    f"âš ï¸ WriteCode returning output with validation errors:\n{error_summary}\n"
                    f"Task may require manual intervention (NEEDS_INFO)"
                )
            
            return final_output
        except Exception as e:
            logger.error(f"âŒ WriteCode hatasÄ±: {e}")
            raise
    
    @staticmethod
    def _parse_code(rsp: str, language: str = "python") -> str:
        """Code block'tan kodu Ã§Ä±kar (backward compatibility)"""
        # Ã–nce FILE manifest formatÄ±nÄ± kontrol et
        if "FILE:" in rsp:
            return rsp  # FILE manifest formatÄ±nda, olduÄŸu gibi dÃ¶ndÃ¼r
        
        # Dile Ã¶zel pattern'ler
        patterns = [
            rf"```{language}(.*?)```",
            r"```(.*)```",
        ]
        
        for pattern in patterns:
            match = re.search(pattern, rsp, re.DOTALL)
            if match:
                return match.group(1).strip()
        
        # HiÃ§bir pattern match etmezse, olduÄŸu gibi dÃ¶ndÃ¼r
        return rsp


class WriteTest(Action):
    """Test yaz (stack-aware)"""
    
    PROMPT_TEMPLATE: str = """
    Kod:
    {code}
    
    Stack: {stack_name}
    Test Framework: {test_framework}
    
    Ã–NEMLÄ°: Bu kod iÃ§in {test_framework} kullanarak TAM OLARAK {k} ADET unit test yaz.
    DAHA FAZLA YAZMA! Sadece {k} adet test yaz.
    
    Kurallar:
    1. TAM OLARAK {k} adet test yaz (daha fazla deÄŸil!)
    2. Her test farklÄ± bir senaryoyu test etmeli:
       - Pozitif senaryo (normal kullanÄ±m)
       - Negatif senaryo (hata durumlarÄ±)
       - Edge case (sÄ±nÄ±r deÄŸerleri)
    3. AynÄ± testi tekrar yazma - her test benzersiz olmalÄ±
    4. Test isimleri aÃ§Ä±klayÄ±cÄ± olsun
    5. {test_framework} syntax'Ä±nÄ± kullan
    
    Sadece {k} adet test yaz, daha fazla deÄŸil!
    
    ```{language}
    {test_template}
    ```
    
    UYARI: Sadece {k} adet test yaz, daha fazla yazma!
    """
    
    name: str = "WriteTest"
    
    @staticmethod
    def _parse_code(rsp: str, language: str = "python") -> str:
        """Code block'tan test kodunu Ã§Ä±kar"""
        patterns = [
            rf"```{language}(.*?)```",
            r"```(.*)```",
        ]
        
        for pattern in patterns:
            match = re.search(pattern, rsp, re.DOTALL)
            if match:
                return match.group(1).strip()
        
        return rsp.strip()
    
    @staticmethod
    def _limit_tests(code: str, k: int) -> str:
        """
        Test kodundan sadece ilk k adet test fonksiyonunu al.
        LLM daha fazla test yazsa bile sadece k adet test dÃ¶ndÃ¼rÃ¼r.
        
        Args:
            code: Test kodu
            k: Maksimum test sayÄ±sÄ±
            
        Returns:
            Sadece k adet test iÃ§eren kod
        """
        lines = code.splitlines()
        result = []
        test_count = 0
        in_test_function = False
        
        for i, line in enumerate(lines):
            # Test fonksiyonu baÅŸlangÄ±cÄ±nÄ± tespit et
            if re.match(r'^\s*def\s+test_', line):
                if test_count >= k:
                    # K adet test bulundu, daha fazlasÄ±nÄ± alma
                    break
                test_count += 1
                in_test_function = True
                result.append(line)
            elif in_test_function:
                # Test fonksiyonu iÃ§indeyiz
                result.append(line)
                # Bir sonraki test fonksiyonu veya dosya sonu gelirse dur
                if i + 1 < len(lines):
                    next_line = lines[i + 1]
                    if re.match(r'^\s*def\s+test_', next_line):
                        # Bir sonraki test baÅŸlÄ±yor, eÄŸer k adet test bulunduysa dur
                        if test_count >= k:
                            break
            else:
                # Test fonksiyonu dÄ±ÅŸÄ±ndayÄ±z (import, class tanÄ±mlarÄ± vs.)
                result.append(line)
        
        # EÄŸer hiÃ§ test bulunamadÄ±ysa orijinal kodu dÃ¶ndÃ¼r
        if test_count == 0:
            return code
        
        return "\n".join(result)
    
    def _get_test_template(self, test_framework: str, language: str, k: int) -> str:
        """Test framework'e gÃ¶re template dÃ¶ndÃ¼r"""
        templates = {
            "pytest": """import pytest

# Test 1: [aÃ§Ä±klama]
def test_1():
    # kod

# Test 2: [aÃ§Ä±klama]
def test_2():
    # kod

# Test {k}: [aÃ§Ä±klama]
def test_{k}():
    # kod""",
            
            "jest": """import {{ describe, it, expect }} from '@jest/globals';

describe('TestSuite', () => {{
  it('Test 1: [aÃ§Ä±klama]', () => {{
    // kod
  }});
  
  it('Test 2: [aÃ§Ä±klama]', () => {{
    // kod
  }});
  
  it('Test {k}: [aÃ§Ä±klama]', () => {{
    // kod
  }});
}});""",
            
            "vitest": """import {{ describe, it, expect }} from 'vitest';

describe('TestSuite', () => {{
  it('Test 1: [aÃ§Ä±klama]', () => {{
    // kod
  }});
  
  it('Test 2: [aÃ§Ä±klama]', () => {{
    // kod
  }});
  
  it('Test {k}: [aÃ§Ä±klama]', () => {{
    // kod
  }});
}});""",
            
            "phpunit": """<?php

use PHPUnit\\Framework\\TestCase;

class MyTest extends TestCase
{{
    public function test1(): void
    {{
        // kod
    }}
    
    public function test2(): void
    {{
        // kod
    }}
    
    public function test{k}(): void
    {{
        // kod
    }}
}}""",
        }
        
        template = templates.get(test_framework.lower(), templates["pytest"])
        return template.replace("{k}", str(k))
    
    @llm_retry()
    async def run(self, code: str, k: int = 3, target_stack: str = None) -> str:
        try:
            # Stack bilgisi
            from .stack_specs import get_stack_spec, infer_stack_from_task
            
            if target_stack:
                spec = get_stack_spec(target_stack)
                if spec:
                    test_framework = spec.test_framework
                    language = spec.language
                    stack_name = spec.name
                else:
                    test_framework = "pytest"
                    language = "python"
                    stack_name = "Python"
            else:
                test_framework = "pytest"
                language = "python"
                stack_name = "Python"
            
            test_template = self._get_test_template(test_framework, language, k)
            
            prompt = self.PROMPT_TEMPLATE.format(
                code=code,
                k=k,
                stack_name=stack_name,
                test_framework=test_framework,
                language=language,
                test_template=test_template
            )
            rsp = await self._aask(prompt)
            raw_code = self._parse_code(rsp, language)
            # Post-process: Test sayÄ±sÄ±nÄ± k ile sÄ±nÄ±rla (LLM daha fazla yazsa bile)
            limited_code = self._limit_tests(raw_code, k)
            logger.debug(f"ğŸ“Š WriteTest: {k} adet test sÄ±nÄ±rÄ± uygulandÄ± ({test_framework})")
            return limited_code
        except Exception as e:
            logger.error(f"âŒ WriteTest hatasÄ±: {e}")
            raise


class ReviewCode(Action):
    """Kodu incele ve geri bildirim ver (stack-aware)"""
    
    PROMPT_TEMPLATE: str = """
    Kod:
    {code}
    
    Testler:
    {tests}
    
    Stack: {stack_name}
    {stack_specific_checks}
    
    Bu kodu ve testleri DÄ°KKATLÄ°CE incele:
    1. Kod kalitesi nasÄ±l? Hata yÃ¶netimi var mÄ±? Input validation var mÄ±?
    2. Test coverage yeterli mi? Edge case'ler test edilmiÅŸ mi?
    3. Docstring'ler/Comment'ler var mÄ±? Kod dokÃ¼mantasyonu yeterli mi?
    4. Stack-specific best practices uygulanmÄ±ÅŸ mÄ±?
    5. GÃ¼venlik: Environment variables, secrets, input sanitization kontrol edilmiÅŸ mi?
    6. Build/Test/Run komutlarÄ± doÄŸru mu? (package.json, composer.json, requirements.txt vs.)
    7. Ä°yileÅŸtirme gereken noktalar var mÄ±?
    
    Ã–NEMLÄ°: EÄŸer kodda eksiklikler, hatalar veya iyileÅŸtirme gereken noktalar varsa MUTLAKA "DEÄÄ°ÅÄ°KLÄ°K GEREKLÄ°" yaz.
    Sadece kod mÃ¼kemmel ve hiÃ§bir sorun yoksa "ONAYLANDI" yaz.
    
    SONUÃ‡: [ONAYLANDI / DEÄÄ°ÅÄ°KLÄ°K GEREKLÄ°]
    
    YORUMLAR:
    - [yorum 1]
    - [yorum 2]
    - [yorum 3]
    """
    
    name: str = "ReviewCode"
    
    def _get_stack_checks(self, stack_id: str) -> str:
        """Stack-specific kontrol listesi"""
        checks = {
            "express-ts": """
Kontrol listesi (Express-TS):
- Middleware sÄ±rasÄ± doÄŸru mu? (body-parser, cors, helmet)
- Error handling middleware var mÄ±?
- TypeScript tipleri tam mÄ±?
- .env iÃ§in dotenv kullanÄ±lmÄ±ÅŸ mÄ±?""",
            
            "nestjs": """
Kontrol listesi (NestJS):
- Module/Controller/Service yapÄ±sÄ± doÄŸru mu?
- Dependency Injection kullanÄ±lmÄ±ÅŸ mÄ±?
- DTO validation var mÄ±?
- Exception filters uygun mu?""",
            
            "laravel": """
Kontrol listesi (Laravel):
- Eloquent relationships doÄŸru mu?
- Request validation kullanÄ±lmÄ±ÅŸ mÄ±?
- Route tanÄ±mlarÄ± RESTful mi?
- Migration dosyalarÄ± var mÄ±?""",
            
            "fastapi": """
Kontrol listesi (FastAPI):
- Pydantic model'ler kullanÄ±lmÄ±ÅŸ mÄ±?
- Async/await doÄŸru kullanÄ±lmÄ±ÅŸ mÄ±?
- Dependency Injection var mÄ±?
- Response model'ler tanÄ±mlanmÄ±ÅŸ mÄ±?""",
            
            "react-vite": """
Kontrol listesi (React-Vite):
- Component yapÄ±sÄ± temiz mi?
- Props type checking (TypeScript) var mÄ±?
- State management doÄŸru mu?
- useEffect dependency array'leri doÄŸru mu?""",
            
            "nextjs": """
Kontrol listesi (Next.js):
- App Router / Pages Router kullanÄ±mÄ± doÄŸru mu?
- Server/Client component ayrÄ±mÄ± yapÄ±lmÄ±ÅŸ mÄ±?
- API routes doÄŸru tanÄ±mlanmÄ±ÅŸ mÄ±?
- Metadata/SEO ayarlarÄ± var mÄ±?""",
            
            "vue-vite": """
Kontrol listesi (Vue-Vite):
- Composition API doÄŸru kullanÄ±lmÄ±ÅŸ mÄ±?
- Reactive state management uygun mu?
- Component props/emits tanÄ±mlanmÄ±ÅŸ mÄ±?
- Script setup syntax kullanÄ±lmÄ±ÅŸ mÄ±?""",
        }
        
        return checks.get(stack_id, "")
    
    @llm_retry()
    async def run(self, code: str, tests: str, target_stack: str = None) -> str:
        try:
            # Stack bilgisi
            from .stack_specs import get_stack_spec
            
            if target_stack:
                spec = get_stack_spec(target_stack)
                if spec:
                    stack_name = spec.name
                    stack_specific_checks = self._get_stack_checks(target_stack)
                else:
                    stack_name = "Python"
                    stack_specific_checks = ""
            else:
                stack_name = "Python"
                stack_specific_checks = ""
            
            prompt = self.PROMPT_TEMPLATE.format(
                code=code,
                tests=tests,
                stack_name=stack_name,
                stack_specific_checks=stack_specific_checks
            )
            rsp = await self._aask(prompt)
            return rsp
        except Exception as e:
            logger.error(f"âŒ ReviewCode hatasÄ±: {e}")
            raise
