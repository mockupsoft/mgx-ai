name: Test Suite

on:
  push:
    branches: [ main, test-cli-workflows-coverage-ci-docs, final-test-and-status-report-phase1-3-coverage-ci, fix/tests-workflow-debug ]
  pull_request:
    branches: [ main, fix/tests-workflow-debug ]
  workflow_dispatch:
  schedule:
    # Nightly performance/regression run (UTC)
    - cron: "0 3 * * *"

jobs:
  test:
    if: github.event_name != 'schedule'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11", "3.12"]

    steps:
    - name: Checkout code
      uses: actions/checkout@v6

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements-dev.txt', 'setup.py', 'pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
        pip install pytest-cov
        pip install -e .

    - name: Lint with flake8 (if available)
      run: |
        pip install flake8 || true
        # stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics || true
        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars too wide
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics || true

    - name: Run unit and integration tests
      run: |
        pytest tests/unit tests/integration --cov=mgx_agent --cov-report=xml --cov-report=term-missing -v

    - name: Run end-to-end tests
      run: |
        pytest tests/e2e --cov=mgx_agent --cov-append --cov-report=xml --cov-report=term-missing -v

    - name: Generate coverage report
      run: |
        coverage report --show-missing
        coverage xml -o coverage.xml

    - name: Upload coverage to Codecov (if token available)
      uses: codecov/codecov-action@v3
      if: ${{ secrets.CODECOV_TOKEN != '' }}
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

    - name: Upload coverage artifacts
      uses: actions/upload-artifact@v3
      with:
        name: coverage-reports-${{ matrix.python-version }}
        path: |
          coverage.xml
          htmlcov/
        retention-days: 7

    - name: Check test count and coverage threshold
      run: |
        echo "Checking test suite requirements..."
        
        # Count total tests
        TEST_COUNT=$(pytest --collect-only -q | grep "test session starts" -A 1 | tail -1 | grep -o '[0-9]*' | head -1)
        echo "Total tests found: $TEST_COUNT"
        
        # Check if we have at least 130 tests
        if [ "$TEST_COUNT" -lt 130 ]; then
          echo "ERROR: Found only $TEST_COUNT tests, but need at least 130 tests"
          exit 1
        fi
        
        # Check coverage percentage
        COVERAGE=$(coverage report | tail -1 | grep -o '[0-9]*%' | head -1 | sed 's/%//')
        echo "Total coverage: ${COVERAGE}%"
        
        if [ "$COVERAGE" -lt 80 ]; then
          echo "ERROR: Coverage is ${COVERAGE}%, but need at least 80%"
          exit 1
        fi
        
        echo "âœ… All requirements met:"
        echo "   - Tests: $TEST_COUNT >= 130"
        echo "   - Coverage: ${COVERAGE}% >= 80%"

  performance:
    name: Performance suite (marked tests)
    runs-on: ubuntu-latest
    # Run on a single Python version to keep results comparable.
    if: |
      github.event_name == 'schedule' ||
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'pull_request' && contains(github.event.pull_request.labels.*.name, 'run-performance'))

    steps:
    - name: Checkout code
      uses: actions/checkout@v6

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-perf-${{ hashFiles('requirements-dev.txt', 'setup.py', 'pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-perf-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
        pip install -e .

    - name: Run performance tests
      run: |
        pytest -o addopts='' -m performance tests/performance -v

    - name: Publish performance summary
      if: always()
      run: |
        echo "## Performance report (baseline vs latest)" >> $GITHUB_STEP_SUMMARY
        if [ -f perf_reports/before_after.md ]; then
          cat perf_reports/before_after.md >> $GITHUB_STEP_SUMMARY
        elif [ -f perf_reports/latest.json ]; then
          echo "(before_after.md not found; showing latest.json)" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          cat perf_reports/latest.json >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        else
          echo "No perf_reports were generated." >> $GITHUB_STEP_SUMMARY
        fi

    - name: Upload perf_reports artifacts
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: perf-reports
        path: |
          perf_reports/
        retention-days: 14

  coverage-report:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/fix/tests-workflow-debug')
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v6

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
        pip install pytest-cov

    - name: Run full test suite with coverage
      run: |
        pytest --cov=mgx_agent --cov-report=html:htmlcov --cov-report=xml:coverage.xml --cov-report=term-missing

    - name: Upload HTML coverage report
      uses: actions/upload-artifact@v3
      with:
        name: coverage-html-report
        path: htmlcov/
        retention-days: 30

    - name: Comment coverage on PR (if PR)
      uses: actions/github-script@v6
      if: github.event_name == 'pull_request'
      with:
        script: |
          const fs = require('fs');
          try {
            const coverage = fs.readFileSync('coverage.xml', 'utf8');
            // Extract coverage percentage from XML
            const match = coverage.match(/line-rate="([0-9.]+)"/);
            if (match) {
              const percentage = (parseFloat(match[1]) * 100).toFixed(1);
              const body = `ðŸ“Š Coverage Report\\n\\nTotal Coverage: **${percentage}%**\\n\\nThis PR maintains test coverage above 80%.`;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
            }
          } catch (error) {
            console.log('Could not read coverage file:', error);
          }